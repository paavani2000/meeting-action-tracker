ğŸ¤ Meeting Action Tracker

An end-to-end solution for capturing, summarizing, and tracking meeting action items.
Upload meeting recordings, automatically generate transcripts, extract summaries and actionable tasks using NLP, and persist them to a database.
Includes a simple React frontend for uploading audio and browsing past meetings.

ğŸ§© Overview

This project is structured into two connected applications:

âš™ï¸ Backend (FastAPI + NLP + PostgreSQL/SQLite)
Processes audio with Whisper, extracts tasks with NLP (spaCy + transformers), summarizes text, and saves everything to the database.

ğŸŒ Frontend (React + Vite + Tailwind)
A lightweight web UI to upload audio files, view transcripts, summaries, and tasks, and browse past meetings.

Together, they provide a seamless pipeline for meeting intelligenceâ€”from raw audio to structured tasks.

ğŸ” Core Features

âœ… Speech-to-Text (STT) â€“ Transcribe meetings using OpenAI Whisper
âœ… Task Extraction â€“ Identify commitments/requests with owners and deadlines
âœ… Summarization â€“ Generate concise meeting summaries
âœ… Persistence â€“ Save transcripts, summaries, and tasks to Postgres (or SQLite)
âœ… Frontend Upload â€“ Upload .wav or .m4a files from browser
âœ… Meeting History â€“ Browse saved meetings and extracted tasks
âœ… Extensible â€“ Ready for Slack/Jira integrations (Phase 5)

ğŸ›  Tech Stack
Layer	Tech Details
ğŸ§ STT	OpenAI Whisper
ğŸ§  NLP	spaCy, Hugging Face Transformers, dateparser
âš™ï¸ Backend	FastAPI, SQLAlchemy, PostgreSQL (or SQLite)
ğŸŒ Frontend	React, Vite, Tailwind CSS
ğŸ”— Integrations (planned)	Slack, Jira, email reminders
ğŸ“¦ Project Structure
MEETING-ACTION-TRACKER/
â”œâ”€ backend/
â”‚  â””â”€ app/
â”‚     â”œâ”€ main.py         # FastAPI entrypoint
â”‚     â”œâ”€ stt.py          # Speech-to-text logic
â”‚     â”œâ”€ nlp.py          # NLP pipeline (tasks + summary)
â”‚     â”œâ”€ models.py       # SQLAlchemy models
â”‚     â”œâ”€ db.py           # DB session + engine
â”‚     â””â”€ init_db.py      # Create tables
â”œâ”€ frontend/
â”‚  â”œâ”€ src/App.jsx        # React UI
â”‚  â””â”€ package.json
â”œâ”€ data/
â”‚  â””â”€ samples/           # Example audio files
â”œâ”€ README.md
â””â”€ requirements.txt

ğŸš€ Getting Started
1. Backend
cd backend
python -m venv venv
source venv/bin/activate   # or venv\Scripts\activate on Windows
pip install -r requirements.txt

# init database
python app/init_db.py

# run server
uvicorn app.main:app --reload


API docs: http://127.0.0.1:8000/docs

2. Frontend
cd frontend
npm install
npm run dev


Frontend runs at http://127.0.0.1:5173

ğŸ›£ Roadmap

 Phase 1 â€“ Speech-to-Text (Whisper)

 Phase 2 â€“ NLP (Summarization + Task Extraction)

 Phase 3 â€“ Persistence (Postgres/SQLite)

 Phase 4 â€“ Frontend (React upload + history)

 Phase 5 â€“ Integrations (Slack, Jira, reminders)

ğŸ“¡ External Services

OpenAI Whisper (speech-to-text)

Hugging Face Transformers (summarization, intent classification)

spaCy (NER, sentence splitting)

ğŸ“– License

MIT License â€“ free to use, modify, and distribute.
